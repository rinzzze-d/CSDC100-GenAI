<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI | Ethics</title>
    <link rel="icon" type="image/x-icon" href="assets/images/icons.png">
    <link href="https://cdn.jsdelivr.net/npm/daisyui@5" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" href="assets/style.css">
</head>
<body>
    <header id="hero">
        <button id="theme-toggle" class="theme-btn"><img id="theme-icon" src="assets/images/light-mode.png" alt="Light Mode Icon"></button>
    </header>
    <nav>
        <a href="index.html">HOME</a>
        <a href="faq.html">FAQs</a>
        <a href="ethics.html">ETHICS</a>
        <a href="article.html">ARTICLE</a>
    </nav>
    <section id="section4" class="section section4">
        <div><img src="assets/images/pillartop.png" alt="Ethics_Introduction"></div>
        <div class="icon-row">
                <img src="assets/images/pillar1.png" alt="ethic1">
                <img src="assets/images/pillar2.png" alt="ethic2">
                <img src="assets/images/pillar3.png" alt="ethic3">
                <img src="assets/images/pillar4.png" alt="ethic4">
        </div>
        <div><img src="assets/images/pillarbottom.png" alt="Ethics_Conclusion"></div>
    </section>

    <section id="section5" class="section section5" alt="Pillar_Top">
    <h1>1. What Ethical AI Means</h1>
    <p>Ethical AI refers to the principles and expectations that guide how artificial intelligence should be designed and used so that it aligns with widely accepted ideas of right and wrong. While morals, ethics, and laws all relate to human behavior, ethics in AI specifically focuses on external standards, such as professional codes, societal norms, and institutional values, that shape responsible development. Because AI reflects the judgments of the people who build it, issues like privacy, surveillance, bias, and discrimination can easily appear in its outputs if ethical safeguards are weak or ignored. Ethical AI therefore seeks to ensure that these systems are created in ways that uphold human dignity, minimize harm, and support fairness and accountability.</p>
    <h1>2. Why Ethical AI Matters</h1>
    <p>AI systems are becoming deeply embedded in everyday life, increasingly influencing decisions, opportunities, and access to services. With this growing power comes an equally significant responsibility: poorly designed or misused AI can cause real harm, spread misinformation, reinforce discrimination, or operate without meaningful oversight. Ethical AI practices help prevent these outcomes by promoting transparency, human oversight, and public accountability. They support the safe and sustainable development of AI, build trust between users and technology, and help ensure that AI enhances society rather than undermining it, even as the technology continues to evolve rapidly.</p>
    </section>

    <section id="section6" class="section section6" alt="Pillar_One">
        <div class="rounded-box">
            <h1>HUMAN RIGHTS & VALUES</h1>
            <p>Artificial intelligence should always place people first. This means designing systems that respect human dignity, protect individual freedoms, and treat everyone fairly. A human-centered approach helps ensure AI supports society rather than reinforcing existing problems.</p>
            <p><b>• Protecting dignity, autonomy, and equality</p></b><p>AI should respect each person’s worth and independence. It must not limit people’s freedom to make choices or treat anyone as less important because of who they are.</p>
            <p><b>• Preventing discrimination and harmful bias</p></b><p>Since AI learns from human-created data, it can unintentionally repeat unfair patterns. Developers must monitor, test, and adjust systems so that they avoid biased or unequal outcomes.</p>
            <p><b>• Ensuring AI supports well-being</p></b><p>Technology should help people, not replace them or put them at risk. Ethical design considers safety, accuracy, and whether the system benefits the individuals who interact with it.</p>
            <p><b>• Encouraging accessible and inclusive design</p></b><p>AI should be usable and beneficial to a wide range of people, including those with different abilities, backgrounds, and needs. This means designing tools that are understandable, available, and sensitive to diverse communities.</p>
        </div>
    </section>

    <section id="section7" class="section section7" alt="Pillar_Two">
        <div class="rounded-box">
            <h1>TRANSPARENCY</h1>
            <p>Transparency is essential for building trust in AI systems. When people understand how an AI works, what data it uses, how decisions are reached, and where human oversight fits in, they are better able to judge whether the system is fair, safe, and appropriate.</p>
            <p><b>• Helping users understand how AI reaches its decisions</p></b><p>The public increasingly expects to know <i>why</i> an AI gives a certain output. Providing explanations, even simple ones, helps users make informed choices and reduces uncertainty about hidden or automated processes.</p>
            <p><b>• Making AI systems open, traceable, and well-documented</p></b><p>Regulations such as GDPR and CCPA require organizations to clearly document how data is collected and used, and to maintain records of how AI systems operate. This traceability allows errors to be caught early and helps ensure systems behave as intended.</p>
            <p><b>• Clearly communicating when AI is involved</p></b><p>Users should always be told when an AI is part of a decision-making process, whether reviewing data, scoring information, or recommending outcomes. Open communication strengthens trust and helps prevent confusion or unintentional reliance on automated results.</p>
            <p><b>• Supporting accountability and reducing misinformation</p></b><p>Transparent systems make it easier to identify incorrect, biased, or misleading outputs. They also clarify who is responsible for the system’s behavior, making oversight more effective and reducing the chance of unnoticed harm.</p><br>
            <p>Transparency ensures AI does not operate as an unseen “black box.” By being open about data practices, decision processes, and system limitations, organizations help create AI that is safer, more trustworthy, and more aligned with public expectations.</p>
        </div>
    </section>

    <section id="section8" class="section section8" alt="Pillar_Three">
        <div class="rounded-box">
            <h1>PRIVACY & SECURITY</h1>
            <p>Privacy and security are essential to ethical AI because these systems often rely on large amounts of personal data. AI can gather information quickly, combine it from many places, and reveal details people never intended to share. When data is handled carelessly or without proper safeguards, individuals can be exposed to surveillance, misuse, and loss of control over their own information.</p>
            <p><b>• Collecting and using personal data responsibly</b></p></b><p>AI should only use data in ways that respect an individual’s expectations and rights. Because AI can analyze enormous datasets in ways humans cannot, it becomes even more important to limit how much information is gathered and ensure it is used for clearly defined, ethical purposes.</p>
            <p><b>• Ensuring privacy safeguards and meaningful consent</b></p></b><p>People deserve to know when their information is being collected, how it will be used, and who will have access to it. Many harms arise when data is gathered silently or shared without permission, especially in systems that track personal behavior.</p>
            <p><b>• Protecting data through secure storage and handling</b></p></b><p>Strong security practices are necessary to prevent leaks, unauthorized access, or large-scale breaches. This includes properly storing data, restricting who can view it, and deleting it when it is no longer needed, steps that become more critical as AI systems process sensitive personal information.</p>
            <p><b>• Reducing risks of surveillance and misuse</b></p></b><p>AI’s ability to combine data from phones, sensors, online activity, and public systems can create powerful tools, but also increases the possibility of invasive monitoring. Ethical use requires careful limits to prevent technologies from being used to track or profile people unfairly.</p>
        </div>
    </section>

    <section id="section9" class="section section9" alt="Pillar_Four">
        <div class="rounded-box">
            <h1>RESPONSIBILITY</h1>
            <p>Ethical AI requires clearly defined responsibility. AI systems do not carry moral or ethical burden, humans do. Because developers, organizations, and decision-makers shape how AI behaves, they must be accountable for the outcomes it produces. </p>
            <p><b>• Assigning responsibility for AI decisions and outcomes</b></p></b><p>AI cannot justify or explain its own actions; the obligation falls on the humans who design, deploy, or oversee the system. Clear roles and responsibilities help ensure that someone is answerable when decisions impact individuals or communities.</p>
            <p><b>• Ongoing monitoring, auditing, and impact assessments</b></p></b><p>Ethical challenges arise when systems operate without oversight. Regular auditing, testing, and documentation help catch harmful patterns early, confirm that the system behaves as intended, and prevent unnoticed drift or misuse.</p>
            <p><b>• Preventing unsafe, misleading, or harmful outputs</b></p></b><p>AI can amplify mistakes at scale if left unchecked. Responsible use means putting safeguards in place to reduce misinformation, limit harmful consequences, and ensure that results remain accurate and safe for real-world use.</p>
            <p><b>• Considering environmental and societal impact</b></p></b><p>Evaluating how AI affects social structures, vulnerable populations, and even resource consumption, ensuring that technological progress does not create new forms of harm.</p>
        </div>
    </section>

    <section id="section10" class="section section10" alt="Pillar_Bottom">
        <div class="rounded-box">
            <h1>WITHIN PRACTICE</h1>
            <p>Ethical AI becomes meaningful only when its principles are applied in real situations. Responsible AI is not just about theory; it requires ongoing processes, human oversight, and careful evaluation at every stage of a system’s life cycle. This focuses on turning ethical guidelines into clear actions that help prevent harm, improve reliability, and ensure AI remains aligned with human values over time.</p>
        </div>
           <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" checked="checked" />
                <div class="collapse-title font-semibold">• Conducting ethical impact assessments before deployment</div>
                <div class="collapse-content text-sm">Before an AI system is released, developers should evaluate how it could affect people, identify possible risks, and determine whether the system aligns with societal expectations. Early assessment helps prevent issues that could become serious once the system is widely used.</div>
        </div>
        <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" />
                <div class="collapse-title font-semibold">• Using high-quality, unbiased training data</div>
                <div class="collapse-content text-sm">Poor or unrepresentative data leads directly to unfair or harmful outcomes. Carefully selecting and reviewing data helps reduce bias and improves the system’s overall trustworthiness.</div>
        </div>
        <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" />
                <div class="collapse-title font-semibold">• Documenting and auditing AI systems regularly</div>
                <div class="collapse-content text-sm">AI must be monitored continuously, not just at launch. Routine testing, auditing, and clear documentation allow organizations to catch errors, track system changes, and ensure that the model behaves consistently.</div>
        </div>
        <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" />
                <div class="collapse-title font-semibold">• Maintaining meaningful human oversight</div>
                <div class="collapse-content text-sm">Humans must remain the final decision-makers in high-stakes or sensitive situations. AI can support analysis and speed, but responsibility and judgment should stay with people to prevent unintended or unjust outcomes.</div>
        </div>
        <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" />
                <div class="collapse-title font-semibold">• Updating AI systems as contexts and rules evolve</div>
                <div class="collapse-content text-sm">AI exists in a fast-changing environment. Laws, social expectations, and real-world conditions shift over time, so systems should be reviewed and improved regularly to ensure they remain safe, lawful, and relevant.</div>
        </div>
        <div class="collapse collapse-plus bg-base-100 border border-base-300">
            <input type="radio" name="my-accordion-3" />
                <div class="collapse-title font-semibold">REFERENCES: </div>
                <div class="collapse-content text-sm"> <ol>
                    <li><b>Julie Mehan. (2024). <i>Artificial Intelligence : Ethical, Social, and Security Impacts for the Present and the Future, Second Edition.</i> ITGP. </b></li>
                    <li><b>Ethics|| Pages:</b>104–110, 135–140</li>
                    <li><b>Human Rights & Values || Pages:</b>290–292, 295–296,305</li>
                    <li><b>Transparency || Pages:</b>112–113, 113–114</li>
                    <li><b>Privacy & Security || Pages:</b>152–156</li>
                    <li><b>Responsibility|| Pages:</b>112–116, 155–156</li>
                    <li><b>Within Practice|| Pages:</b>112–116, 50–156, 289–305</li>
                    </ol>
                </div>
        </div>
    </section>

    <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
    <script src="assets/script.js"></script>
</body>
</html>